# Сортировки и асимптотика

[toc]

##	Асимптотика

###	Пример разницы

```c++
for (int i = 0; i < n; ++i) {
  cout << "*";
}
```

Сколько итераций пройдет при `n = 10`, а при `n = 10 000`?

Какой характер имеет зависимость количества итераций от `n`?

```c++
for (int i = 0; i < 3*n; ++i) {
  for (int j = 0; j < 4*n; ++j) {
    for (int j = 0; j < 1*n; ++j) {
      cout << "ora";
    }   
  }
}
```

Сколько итераций пройдет при `n = 10`, а при `n = 10 000`?

Какой характер имеет зависимость количества итераций от `n`?

```c++
for (int i = 0; i < n; i*=i) {
  cout << "*";
}
```

Сколько итераций пройдет при `n = 10`, а при `n = 10 000`?

Какой характер имеет зависимость количества итераций от `n`?

###	Что такое O?

[Формально](https://ru.wikipedia.org/wiki/%C2%ABO%C2%BB_%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%BE%D0%B5_%D0%B8_%C2%ABo%C2%BB_%D0%BC%D0%B0%D0%BB%D0%BE%D0%B5)

Если это определение ОЧЕНЬ СИЛЬНО упростить, то получаем, что “O” - это исходная функция, из которой были выкинуты все константы. **ЭТО НЕ ЯВЛЯЕТСЯ ПРАВИЛЬНЫМ ОПРЕДЕЛЕНИЕМ**:

$$Сn = O(n)$$, где С - константа
$$Сn^2 = O(n^2) $$, где С - константа
$$C_1\log_{C_2}n = O(log_e n)$$, где $$ C_1,C_2 $$ - константы

## Сортировки

###	Сортировка вставками.

Суть алгоритма заключается в том, что мы делаем так, что слева находится уже отсортированная часть массива (на картинке обозначена черным цветом), размер которой на каждой итерации цикла увеличивается на 1. Таким образом, мы каждый раз ищем место для нового элемента в отсортированной части и увеличиваем размер этой части на 1. Поскольку каждый раз мы проделываем O(n) сравнений (пока ищем место для элемента), а потом еще O(n) сдвигов, пока вставляем его на нужное место, то в целом каждая итерация стоит нам O(n) операций. Таких итераций нам, в свою очередь, понадобится столько, сколько элементов в массиве, поскольку мы всегда просто вставляем новый элемент, следовательно, общая асимптотика: n*O(n) = O(n^2)

![](https://upload.wikimedia.org/wikipedia/commons/0/0f/Insertion-sort-example-300px.gif)

```pseudocode
function insertionSort(a):
  for i = 1 to n - 1
    j = i - 1
    while j ⩾ 0 and a[j] > a[j + 1] 
      swap(a[j], a[j + 1])
      j--
```



###	Сортировка пузырьком.

Этот алгоритм в какой-то степени напоминает рассмотренный нами ранее. Здесь мы на каждой итерации внешнего цикла пытаемся поставить на место один элемент (тот который окажется в самом конце), что напоминает "всплывание пузырька". Делаем мы это при помощи попарного сравнения двух элементов массива, и, при неправильном их порядке, перестановкой их местами. Таким образом за n - 1 итерацию внешнего цикла мы однозначно поставим на место n - 1 элемент, а последний уже однозначно окажется на первом месте. 

![](https://upload.wikimedia.org/wikipedia/commons/c/c8/Bubble-sort-example-300px.gif)

```pseudocode
function bubbleSort(a):
  for i = 0 to n - 2
    for j = 0 to n - 2
      if a[j] > a[j + 1]
        swap(a[j], a[j + 1])
```
Этот алгоритм можно усовершенствовать двумя способами:
	1. Мы точно знаем, что на i-ой итерации цикла, i последних элементов уже точно стоят на своих местах, поэтому первое, что можно усовершенствовать, это внутренний цикл проводить не до n - 2, а до n - i - 2.
	2. Если мы провели итерацию цикла, и во время нее не проделали ни одного swap, то, очевидно, массив  уже отсортирован, и дальнейшие итерации бесполезны.

Проводя две эти оптимизации, получаем такой код:

```pseudocode
function bubbleSort(a):
  i = 0
  anyChanges = true
  while anyChanges
    anyChanges = false
    for j = 0 to n - i - 2
      if a[j] > a[j + 1]
        swap(a[j], a[j + 1])
        anyChanges = true
    i = i + 1
```

###	Сортировка выбором.

Писать лень, читаем [тут](https://neerc.ifmo.ru/wiki/index.php?title=Сортировка_выбором).

![](http://i.stack.imgur.com/avlC6.gif)

```pseudocode
function selectionSort(a):
   for i = 0 to n - 2
     min = i
     for j = i + 1 to n - 1
       if a[j] < a[min]
         min = j
     swap(a[i], a[min])
```



###	Сортировка подсчётом.

####	Простейшая (неустойчивая)

Пусть у нас есть ограниченный размер алфавита (подразумевается, что либо числа в каком-то диапазоне, либо буквы и тд), тогда существует возможность отсортировать массив наших данных за O(n). Делается это очень просто. Выделаем новый массив размера нашего алфавита, где изначально значение в каждой ячейке равно 0. После этого мы проходимся по нашему исходному массиву, увеличивая значение ячейки, отвечающей за конкретный элемент, на 1. Теперь проходимся по полученному массиву и записываем элемент столько раз, сколько это указано в нашем массиве.

Таким образом, за два прохода по массиву, мы научились его сортировать. 

Минус алгоритма в том, что его можно применять ТОЛЬКО на массиве с ограниченным алфавитом, иначе размер второго массива будет слишком большим, и проход по нему (равный его размеру) будет занимать O(max_element), где max_element - значение максимального элемента в массиве. 

![](http://sorting.valemak.com/wp-content/uploads/2013/12/sort_counting.gif)

```pseudocode
function simpleCountingSort(A: int[n]): 
    for number = 0 to k - 1
        C[number] = 0 
    for i = 0 to n - 1
        C[A[i]] = C[A[i]] + 1;     
    pos = 0;
    for number = 0 to k - 1
        for i = 0 to C[number] - 1
            A[pos] = number;
            pos = pos + 1;
```



####	С дополнительным массивом (устойчивая)

Теперь предположим, что наши с вами объекты были не совсем одинаковыми. Например, 1, стоявшая на 3 месте в исходном массиве,была красная, а та, которая стояла на 10 - синяя. Нам важно в результирующем массиве сделать так, чтобы 1(красная) стояла строго раньше 1(синяя). Это называется свойством **устойчивости** сортировки. Заметим, что первый вариант алгоритма не был устойчивым. Почему? Потому что мы вообще не различаем единички друг между другом. А в ответ пихаем первую попавшуюся. Научимся решать эту проблему. 

Пусть исходный массив - А. Массив, в котором будем хранить результат - В. Массив для записи частоты встречаемости элементов - P.

![](https://neerc.ifmo.ru/wiki/images/f/f6/Building_P.png)

Первый шаг алгоритма такой же, как и в простой реализации: записываем в Р частоты встречаемости каждого элемента. Теперь переведем частоты встречаемости в индекс начала блока, ответственного за i-ый набор элементов. Для этого заведем переменную carry, которая будет отвечать за местонахождение начала текущего блока. (для нулей зеленый блок, для 2 - желтый, для 3 - фиолетовый)

![](https://neerc.ifmo.ru/wiki/images/e/e0/P_as_array_of_pointers.png)

Теперь просто пройдемся по исходному массиву А, записывая текущий элемент в ячейку, указанную СЕЙЧАС в `P[A[i]]`, после чего значение в этой ячейке увеличиваем на 1, чтобы следующий встреченный элемент поместить в следующую ячейку нужного блока.

Таким образом, алгоритм все еще работает за линейное время, но требует O(n) дополнительной памяти.

```pseudocode
function complexCountingSort(A: int[n], B: int[n]):
    for i = 0 to k - 1
        P[i] = 0;         
    for i = 0 to length[A] - 1
        P[A[i].key] = P[A[i].key] + 1;     
    carry = 0;
    for i = 0 to k - 1
        temporary = P[i];
        P[i] = carry;
        carry = carry + temporary;     
    for i = 0 to length[A] - 1
        B[P[A[i].key]] = A[i];
        P[A[i].key] = P[A[i].key] + 1;
```

На картинке продемонстрирован этот алгоритм, только запись там идет справа налево (такая реализация тоже возможна, отличается только тем, что здесь мы записываем правое положение блока, поэтому и идем справа налево).

![slowgif](https://raw.githubusercontent.com/PavelEfarinov/CPPCourse/master/Notes/slowgif.gif)

###	Цифровая сортировка

Это алгоритм, работающий за O(m*max(k, n)), где m - количество разрядов у числа, n - размер массива, k - размер алфавита.

Тогда применяя алгоритм сортировки подсчетом поразрядно, мы сможем отсортировать все числа.

Единственное, важно помнить, что при использовании неустойчивого алгоритма у вас ничего не получится. (Почему?)

![](https://neerc.ifmo.ru/wiki/images/thumb/8/8a/%D0%A6%D0%B8%D1%84%D1%80%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0.png/450px-%D0%A6%D0%B8%D1%84%D1%80%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0.png) 

```pseudocode
 function radixSort(int[] A):
     for i = 1 to m               
         for j = 0 to k - 1                              
             C[j] = 0                                  
         for j = 0 to n - 1
             d = digit(A[j], i) // возвращает значение i-ого разряда числа
             C[d]++
         count = 0
         for j = 0 to k - 1
             tmp = C[j]
             C[j] = count
             count += tmp
         for j = 0 to n - 1
             d = digit(A[j], i)                             
             B[C[d]] = A[j]            
             C[d]++
         A = B
```



##	Понятие сложности алгоритма. Линейные и квадратичные алгоритмы.

Мы рассмотрели несколько алгоритмов сортировки, некоторые из них работали за квадратичное время, некоторые - за линейное. Почему так важно стараться оптимизировать алгоритм? Рассмотрим зависимость времени, необходимой на выполнение алгоритма, от его размера.

![](https://habrastorage.org/getpro/habr/post_images/195/e1f/6a1/195e1f6a1379554ca9025338301a78ed.png)